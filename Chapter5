机器学习基础：
P63
机器学习本质上属于应用统计学，更多地关注如何用计算机统计的估计复杂函数，不太关注为这些函数提供置信区间。
所谓学习，Mitchell (1997)提供了一个简洁的定义：“对于某类任务T和性能度量P，一个计算机程序被认为可以从经验E中学习是指，通过经验E改进后，它在任务T上由性能度量P衡量的性能会有所提升。”
通常机器学习任务定义为机器学习系统应该如何处理样本（example），样本是指我们从某些希望机器学习系统处理的对象或事件中收集到的已经量化的特征（feature）的集合。通常将样本表示成一个向量

其中向量的每一个元素xi是一个特征。例如一张图片可以是一个样本，它的特征是各个像素值。

P66 5.1.2性能度量
通常我们会更加关注机器学习算法在未观测数据上的性能如何，因为这将决定其在实际应用中的性能。因此我们使用测试集（test set）数据来评估系统性能，将其与训练机器学习系统的训练集数据分开。性能度量有时是困难的，某些情况下不确定应该度量什么，还有些情况我们知道应该度量哪些值，但度量他们不太现实。

P70 5.2容量、过拟合和欠拟合
机器学习的主要挑战是我们的算法必须能够在先前未观测到的新输入上表现良好，而不只是在训练集上表现良好。在先前未观测到的输入上表现良好的能力被称为泛化（generalization）
训练机器学习模型时我们可以使用某个训练集，在训练集上计算一些被称为训练误差（training error）的度量误差，目标是降低训练误差。这是优化问题。机器学习和优化不同的地方在于，机器学习也希望降低泛化误差（generalization error）也被称为测试误差（test error）。泛化误差被定义为新输入的误差期望，这里，期望的计算基于不同的可能输入，这些输入采自系统在现实中遇到的分布。
通常我们度量模型在训练集中分出来的测试集（test set）样本上的性能，来评估机器学习模型的泛化误差。
以下是决定机器学习算法效果是否好的因素：
1）降低训练误差
2）缩小训练误差和测试误差的差距。
这两个因素对应机器学习的两个主要挑战：欠拟合（underfitting）和过拟合（overfitting）。欠拟合是指模型不能在训练集上获得足够低的误差，而过拟合是指训练误差和测试误差之间的差距太大。
通过调整模型的容量（capacity）我们可以控制模型是否偏向于过拟合或者欠拟合。通俗来讲，模型的容量是指其拟合各种函数的能力。
一种控制训练算法容量的方法是选择假设空间（hypothesis space），即学习算法可以选择为解决方案的函数集。
模型规定了调整参数降低训练目标时，学习算法可以从哪些函数组中选择函数。这被称为模型的表示容量（representational capacity）。在很多情况下，从这些函数中挑选出最优函数是非常困难的优化问题。实际中，学习算法很少真的找到最优函数，而仅是找到一个可以大大降低训练误差的函数。额外的限制因素，比如优化算法的不完美，意味着学习算法的有效容量（effective capacity）可能小于模型组的表示容量。
奥卡姆剃刀（Occam's razor），在同样能够解释一直观测现象的假设中，我们应该挑选“最简单”的那个。
P73页图

P74正则化
算法的效果不仅很大程度上受影响于假设空间的函数数量，也取决于这些函数的具体形式。可以加入权重衰减（weight decay）来修改线性回归的训练标准。更一般地，正则化一个学习函数f(x;theta)的模型，我们可以给代价函数添加被称为正则化项（regularizer）的惩罚。正则化（regularization）是指修改学习算法，使其降低繁华误差而非训练误差。

P94 5.9 随机梯度下降
几乎所有的深度学习算法都用到了一个非常重要的算法：随机梯度下降（stochastic gradient descent, SGD）
随机梯度下降的核心是，梯度是期望。

P96 5.10 构建机器学习算法
几乎所有的深度学习算法都可以被描述为一个相当简单的配方：特定的数据集，代价函数，优化过程和模型。我们可以将不同算法视为出于相同原因解决相关问题的一类方法，而不是一长串各个不同的算法。
促进深度学习发展的一部分原因是传统学习算法在语音识别或者对象识别类人工智能问题上泛化能力不足。
